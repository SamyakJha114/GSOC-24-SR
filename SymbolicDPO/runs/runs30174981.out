Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torch in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (2.4.0)
Requirement already satisfied: filelock in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (3.15.4)
Requirement already satisfied: typing-extensions>=4.8.0 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (4.9.0)
Requirement already satisfied: sympy in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (1.12)
Requirement already satisfied: networkx in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (3.2.1)
Requirement already satisfied: jinja2 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (3.1.2)
Requirement already satisfied: fsspec in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (2023.12.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (9.1.0.70)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: triton==3.0.0 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (3.0.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.68)
Requirement already satisfied: MarkupSafe>=2.0 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)
Requirement already satisfied: mpmath>=0.19 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from sympy->torch) (1.3.0)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: deap in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (1.4.1)
Requirement already satisfied: numpy in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from deap) (1.26.3)
current file index :-  7
1000000
Cycle 1/4
Length of seed expression array :- 67
num_cores  128
67 64
gen	nevals	avg        	std        	min      	max        
0  	0     	4.91271e+16	4.88801e+17	0.0263914	4.91263e+18
1  	60    	inf        	nan        	0.00538834	inf        
2  	70    	inf        	nan        	0.00494742	inf        
3  	72    	1.38287e+27	1.36854e+28	0.00219315	1.37549e+29
4  	57    	2.69962e+83	2.68609e+84	0.00219315	2.69962e+85
5  	67    	1.08985e+113	1.08438e+114	0.00219315	1.08985e+115
6  	58    	4.00443e+185	inf         	0.00219315	4.00443e+187
7  	59    	1.95564e+42 	1.94584e+43 	0.0021633 	1.95564e+44 
Best individual: mul(protected_log(mul(mul(-1, protected_log(mul(mul(-1, protected_log(3)), 3))), s_3)), protected_pow(3, mul(cos(abs(3)), s_3)))
Fitness: (0.002163296433913218,)
R2_score with noisy data: 0.9999552072385002
R2_score with original data: 0.9999551946400097
best :-  mul(protected_log(mul(mul(-1, protected_log(mul(mul(-1, protected_log(3)), 3))), s_3)), protected_pow(3, mul(cos(abs(3)), s_3)))
GENERATING PREFERENCE PAIRS
1424
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.42874140219463336
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.36690223510084036
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.33241871628467434
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.30349494457583537
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.3018082957975306
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.3011666728652545
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.2997362321125461
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.29839238395484596
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.2983748930591074
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.2982869941376514
Cycle 2/4
Length of seed expression array :- 72
num_cores  128
72 72
gen	nevals	avg        	std        	min       	max        
0  	0     	1.80501e+06	7.38859e+06	0.00532548	7.25649e+07
1  	57    	304148     	3.00977e+06	0.00532548	3.02509e+07
2  	64    	10217.8    	98281.6    	0.00260066	987932     
3  	64    	10299.8    	98328.7    	0.00260066	987932     
4  	66    	399.906    	3783.44    	0.00260066	38014.6    
5  	68    	973.788    	8912.39    	0.00260066	89522.2    
6  	50    	45.1634    	439.476    	0.00189469	4417.57    
7  	67    	5.78818    	47.4545    	0.00189469	475.326    
Best individual: protected_div(cos(protected_log(pi)), mul(abs(s_2), 4))
Fitness: (0.0018946923163982263,)
R2_score with noisy data: 0.9999607688989297
R2_score with original data: 0.9999609129074928
best :-  protected_div(cos(protected_log(pi)), mul(abs(s_2), 4))
GENERATING PREFERENCE PAIRS
1462
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.3578997428471945
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.3011862990512912
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.3015341203078488
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.24543307528736377
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.24220841725333714
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.24055190945302432
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.24127388843061498
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.23261816576112843
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.23339797099121212
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.2341118936005625
Cycle 3/4
Length of seed expression array :- 50
num_cores  128
50 50
gen	nevals	avg       	std        	min       	max       
0  	0     	7.7572e+15	7.71832e+16	0.00210673	7.7572e+17
1  	69    	101.406   	1002.1     	0.00210673	10072.2   
2  	51    	5.69177   	52.0364    	0.00210673	522.883   
3  	60    	107.501   	669.286    	0.00210673	5386.94   
4  	53    	11.8966   	112.164    	0.00210673	1127.61   
5  	61    	1030.68   	7511.01    	0.00210673	74193.5   
6  	61    	440.54    	4041.78    	0.00210673	40562.1   
7  	60    	291845    	2.90373e+06	0.00210673	2.91836e+07
Best individual: protected_div(protected_log(s_1), protected_exp(pi))
Fitness: (0.0021067284372159375,)
R2_score with noisy data: 0.9999563785235561
R2_score with original data: 0.9999564728576611
best :-  protected_div(protected_log(s_1), protected_exp(pi))
GENERATING PREFERENCE PAIRS
1516
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.26176970736917393
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.21620223802064456
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.23514418635283943
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.18335343805077425
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.07771778492605061
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.06973562883072472
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.06948990085339043
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.06800236975122387
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.06723470772483629
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.06656082313470166
Cycle 4/4
Length of seed expression array :- 25
num_cores  128
25 25
gen	nevals	avg        	std       	min       	max        
0  	0     	2.51944e+09	2.5068e+10	0.00532548	2.51943e+11
1  	42    	208.356    	1464.77   	0.00532548	11746.6    
2  	59    	10415.9    	98271.9   	0.00337162	987932     
3  	62    	9901.58    	98295.9   	0.00172691	987932     
4  	60    	106.1      	1001.82   	0.00172589	10072.2    
5  	56    	4.2138e+82 	4.19267e+83	0.00172589	4.2138e+84 
6  	61    	22.7649    	125.122    	0.00172589	907.473    
7  	70    	2893.23    	21706      	0.00172589	209780     
Best individual: protected_div(tanh(sin(sin(3))), s_3)
Fitness: (0.0017258933647172163,)
R2_score with noisy data: 0.9999642640145623
R2_score with original data: 0.999964357164606
best :-  protected_div(tanh(sin(sin(3))), s_3)
GENERATING PREFERENCE PAIRS
1532
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 2.4366040407375693
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.4423184336579468
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.21768268451673506
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.3677429788749612
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.10031540380040954
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.10332581365996822
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.09106089698838829
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.08669047886045847
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.08617368644068946
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.08390996594242553
current file index :-  8
1000000
Cycle 1/4
Length of seed expression array :- 75
num_cores  128
75 65
gen	nevals	avg        	std        	min    	max        
0  	0     	7.82349e+11	7.78427e+12	10.4781	7.82349e+13
1  	60    	inf        	nan        	10.4781	inf        
2  	67    	26468.8    	209168     	10.4781	2.03709e+06
3  	63    	61797.1    	305472     	10.4781	2.03709e+06
4  	53    	inf        	nan        	10.4781	inf        
5  	67    	inf        	nan        	10.4781	inf        
6  	57    	6.01246e+18	5.98232e+19	10.4781	6.01246e+20
7  	53    	2.42686e+199	inf        	10.4781	2.42686e+201
Best individual: mul(s_1, s_2)
Fitness: (10.478083258187008,)
R2_score with noisy data: 0.9999795172040891
R2_score with original data: 0.9999797739977535
best :-  mul(s_1, s_2)
GENERATING PREFERENCE PAIRS
1018
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.46293624563544405
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.4067791844992077
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.34453577716268746
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.32434475033854443
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.32219248139025536
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.3200013681917506
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.3183673478014694
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.3161345677651173
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.3161400503013283
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.3160428787289443
Cycle 2/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg        	std        	min    	max        
0  	0     	2.66709e+30	2.65372e+31	10.4781	2.66709e+32
1  	57    	41879.4    	265665     	10.4781	2.58682e+06
2  	58    	6.08334e+12	5.57289e+13	10.4781	5.58369e+14
3  	56    	299728     	2.90608e+06	10.4781	2.92096e+07
4  	51    	1.94787e+12	1.9381e+13 	10.4781	1.94787e+14
5  	62    	1.69524e+07	1.6865e+08 	10.4781	1.695e+09  
6  	69    	1.69604e+07	1.68649e+08	10.4781	1.695e+09  
7  	58    	9325.09    	60542.9    	10.4781	486271     
Best individual: mul(s_1, s_2)
Fitness: (10.478083258187008,)
R2_score with noisy data: 0.9999795172040891
R2_score with original data: 0.9999797739977535
best :-  mul(s_1, s_2)
GENERATING PREFERENCE PAIRS
1476
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.18636693468225357
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.1765978842982755
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.13987056452743993
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.14236904864975333
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.1381952221830992
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.13597708798290506
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.13516449082148815
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.13415348020011938
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.13396435015023156
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.13412067358847315
Cycle 3/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg    	std    	min    	max    
0  	0     	732.461	5679.97	10.4781	56572.6
1  	55    	inf    	nan    	10.4781	inf    
2  	53    	20117.3	158795 	10.4781	1.52919e+06
3  	54    	9.16881e+82	5.77924e+83	10.4781	4.16108e+84
4  	53    	4.16108e+82	4.14022e+83	10.4781	4.16108e+84
5  	68    	4.16108e+82	4.14022e+83	7.79005	4.16108e+84
6  	67    	7.04655e+12	7.01123e+13	10.4781	7.04655e+14
7  	59    	3863.92    	28305.6    	10.4781	262166     
Best individual: mul(s_1, protected_div(s_2, tan(protected_sqrt(1))))
Fitness: (7.790054775852077,)
R2_score with noisy data: 0.9999847718234168
R2_score with original data: 0.9999851034282459
best :-  mul(s_1, protected_div(s_2, tan(protected_sqrt(1))))
GENERATING PREFERENCE PAIRS
1510
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.14633654324375853
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.07113619982153094
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.05817978429793767
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.04440963597697119
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.02743026844945822
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.026466390043038274
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.02631717301554448
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.025838181973311048
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.025536500545890496
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.025478124318774477
Cycle 4/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg    	std   	min    	max        
0  	0     	84676.1	837511	10.4781	8.41776e+06
1  	58    	347807 	3.35049e+06	10.4781	3.36782e+07
2  	62    	5.27099e+11	5.24457e+12	10.4781	5.27099e+13
3  	60    	9053.14    	55093.9    	10.4781	472856     
4  	61    	28076.9    	127156     	10.4781	965807     
5  	66    	9.18088e+46	9.13486e+47	10.4781	9.18088e+48
6  	60    	2.05875e+13	1.19934e+14	10.4781	8.12989e+14
7  	62    	1.094e+07  	8.87809e+07	10.4781	8.64653e+08
Best individual: mul(s_1, s_2)
Fitness: (10.478083258187008,)
R2_score with noisy data: 0.9999795172040891
R2_score with original data: 0.9999797739977535
best :-  mul(s_1, s_2)
GENERATING PREFERENCE PAIRS
1526
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.40812205692675446
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.614413543644627
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.17216138594594305
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.13328619283450743
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.07018646467857179
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.05214277945933666
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.055949642569021754
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.05864938959370793
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.061101859358377836
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.05837170777742013
current file index :-  9
1000000
Cycle 1/4
Length of seed expression array :- 75
num_cores  128
75 73
gen	nevals	avg        	std        	min    	max        
0  	0     	7.83948e+11	7.80019e+12	1.03103	7.83948e+13
1  	50    	7.79965e+96	7.76055e+97	1.03103	7.79965e+98
2  	60    	7.79965e+96	7.76055e+97	1.03103	7.79965e+98
3  	64    	2.92003e+10	2.90538e+11	1.03103	2.92002e+12
4  	54    	4.08249e+161	inf        	1.03103	4.08249e+163
5  	59    	1.9701e+23  	1.96022e+24	1.03103	1.9701e+25  
6  	56    	4.9221e+06  	3.42016e+07	1.03103	2.82621e+08 
7  	57    	1.23691e+10 	1.23071e+11	1.03103	1.23691e+12 
Best individual: mul(mul(mul(s_1, s_2), s_4), protected_pow(s_3, -1))
Fitness: (1.031026065797293,)
R2_score with noisy data: 0.9999995068228392
R2_score with original data: 1.0
best :-  mul(mul(mul(s_1, s_2), s_4), protected_pow(s_3, -1))
GENERATING PREFERENCE PAIRS
1454
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.39244532207511873
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.3215484577741423
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.32903980978522196
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.2747145241480448
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.26516081844711653
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.26090657607371576
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.2561512328987329
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.24869451122613598
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.24824640785873395
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.24791852203963247
Cycle 2/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg    	std    	min    	max    
0  	0     	757.286	4611.67	1.03103	43665.2
1  	58    	1.32375e+82	1.12833e+83	1.03103	1.11712e+84
2  	53    	inf        	nan        	1.03103	inf        
3  	58    	1.07744e+48	1.07204e+49	1.03103	1.07744e+50
4  	57    	2.14579e+06	1.85654e+07	1.03103	1.8475e+08 
5  	46    	2.68349e+57	2.67004e+58	1.03103	2.68349e+59
6  	73    	3.96002e+154	inf        	1.03103	3.96002e+156
7  	61    	1.49288e+07 	1.2299e+08 	1.03103	1.21968e+09 
Best individual: mul(mul(mul(s_1, s_2), s_4), protected_pow(s_3, -1))
Fitness: (1.031026065797293,)
R2_score with noisy data: 0.9999995068228392
R2_score with original data: 1.0
best :-  mul(mul(mul(s_1, s_2), s_4), protected_pow(s_3, -1))
GENERATING PREFERENCE PAIRS
1334
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.10512197791291301
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.07810006867105194
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.06628335365086489
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.059261426166119145
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.058357367467542935
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.05788792279315021
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.05742397440267738
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.056945913252508286
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.056834330180168195
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.056959798385767375
Cycle 3/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg    	std    	min    	max    
0  	0     	1107.73	1010.83	1.03103	3004.09
1  	52    	4.65095e+11	4.62763e+12	1.03103	4.65095e+13
2  	43    	5.59544e+08	4.26694e+09	1.03103	4.03532e+10
3  	60    	1.95896e+72	1.94914e+73	1.03103	1.95896e+74
4  	76    	inf        	nan        	1.03103	inf        
5  	58    	8.03668e+24	7.9964e+25 	1.03103	8.03668e+26
6  	60    	1.37867e+24	1.37176e+25	1.03103	1.37867e+26
7  	61    	1.06496e+07	6.3931e+07 	1.03103	5.06925e+08
Best individual: mul(mul(mul(s_1, s_2), s_4), protected_pow(s_3, -1))
Fitness: (1.031026065797293,)
R2_score with noisy data: 0.9999995068228392
R2_score with original data: 1.0
best :-  mul(mul(mul(s_1, s_2), s_4), protected_pow(s_3, -1))
GENERATING PREFERENCE PAIRS
1446
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.3260785131880632
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.2197321404360311
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.08206596439237451
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.07605272647570475
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.05850250283891184
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.045047618003114895
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.036596428313968234
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.0337584541440135
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.033704482498567966
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.033957815791548315
Cycle 4/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg   	std    	min    	max    
0  	0     	520.84	1590.76	1.03103	15505.6
1  	57    	86642.2	838895 	1.03103	8.43181e+06
2  	64    	5.49169e+289	inf    	1.03103	5.49169e+291
3  	52    	6.25219e+12 	6.22085e+13	1.03103	6.25219e+14 
4  	60    	3.66246e+252	inf        	1.03103	3.66246e+254
5  	57    	3.20821e+06 	2.20091e+07	1.03103	2.10412e+08 
6  	61    	9.68953e+41 	9.64096e+42	1.03103	9.68953e+43 
7  	43    	3.67797e+154	inf        	1.03103	3.67797e+156
Best individual: mul(mul(mul(s_1, s_2), s_4), protected_pow(s_3, -1))
Fitness: (1.031026065797293,)
R2_score with noisy data: 0.9999995068228392
R2_score with original data: 1.0
best :-  mul(mul(mul(s_1, s_2), s_4), protected_pow(s_3, -1))
GENERATING PREFERENCE PAIRS
1296
