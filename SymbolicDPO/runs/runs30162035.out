Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torch in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (2.4.0)
Requirement already satisfied: filelock in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (3.15.4)
Requirement already satisfied: typing-extensions>=4.8.0 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (4.9.0)
Requirement already satisfied: sympy in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (1.12)
Requirement already satisfied: networkx in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (3.2.1)
Requirement already satisfied: jinja2 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (3.1.2)
Requirement already satisfied: fsspec in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (2023.12.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (9.1.0.70)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: triton==3.0.0 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (3.0.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.68)
Requirement already satisfied: MarkupSafe>=2.0 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)
Requirement already satisfied: mpmath>=0.19 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from sympy->torch) (1.3.0)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: deap in /global/homes/s/samyak09/.local/perlmutter/python-3.11/lib/python3.11/site-packages (1.4.1)
Requirement already satisfied: numpy in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from deap) (1.26.3)
current file index :-  0
1000000
Cycle 1/4
Length of seed expression array :- 73
num_cores  128
73 69
gen	nevals	avg      	std        	min       	max      
0  	0     	7.175e+11	7.13903e+12	0.00705559	7.175e+13
1  	60    	7.175e+11	7.13903e+12	0.0049935 	7.175e+13
2  	58    	1.435e+12	1.0045e+13 	0.0049935 	7.175e+13
3  	62    	7.175e+11	7.13903e+12	0.0049935 	7.175e+13
4  	59    	9.49391  	61.0839    	0.0049463 	572.251  
5  	62    	1.38108  	10.1436    	0.00490219	101.274  
6  	66    	2.9179   	23.334     	0.00277109	234.09   
7  	57    	22.2945  	153.345    	0.00277109	1507.86  
Best individual: protected_div(protected_log(protected_log(pi)), sub(protected_sqrt(3), cos(s_1)))
Fitness: (0.0027710850211472497,)
R2_score with noisy data: 0.999971590963487
R2_score with original data: 0.999971590963487
best :-  protected_div(protected_log(protected_log(pi)), sub(protected_sqrt(3), cos(s_1)))
GENERATING PREFERENCE PAIRS
1502
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.4499217635452353
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.37358210811897224
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.29203095895219716
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.24819842964065392
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.23761409400370195
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.23510415798719256
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.23351980174046677
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.23215292876321106
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.2320389957028435
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.2319234935196721
Cycle 2/4
Length of seed expression array :- 0
num_cores  128
0 0
gen	nevals	avg    	std   	min       	max        
0  	0     	15456.6	120874	0.00780376	1.20243e+06
1  	55    	6.49053	40.9099	0.00780376	400.293    
2  	63    	34.1266	297.1  	0.00780376	2972.42    
3  	60    	0.570742	1.61378	0.00780376	11.3825    
4  	66    	6.57177 	56.3749	0.00780376	567.291    
5  	56    	1347.75 	13106.1	0.00737653	131718     
6  	66    	1.7882  	6.80022	0.00737653	53.4517    
7  	61    	4.31998 	25.7351	0.00737653	205.701    
Best individual: mul(sin(2), sin(3))
Fitness: (0.0073765324325971255,)
R2_score with noisy data: 0.9999243761279001
R2_score with original data: 0.9999243761279001
best :-  mul(sin(2), sin(3))
GENERATING PREFERENCE PAIRS
824
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.07885681032147034
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.07050666878145771
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.08382441362622756
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.05470612299216895
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.055967450724334
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.057696719721053634
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.05940419373541498
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.05907853403835591
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.059320344759013884
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.059113451248667404
Cycle 3/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg    	std    	min      	max    
0  	0     	9.26666	53.2242	0.0110121	531.878
1  	60    	29.7498	284.92 	0.00882022	2864.38
2  	54    	3.72957	21.4746	0.00828897	206.089
3  	57    	6.18781	46.0644	0.00287912	437.721
4  	58    	1170.02	8211.46	0.00229881	63482.4
5  	61    	0.843356	3.29364	0.00229881	26.197 
6  	60    	11.8383 	97.198 	0.00229881	956.543
7  	55    	7.04794e+11	7.01261e+12	0.00149629	7.04794e+13
Best individual: mul(sin(3), sin(sin(add(cos(s_1), tanh(abs(3))))))
Fitness: (0.0014962896727553836,)
R2_score with noisy data: 0.9999846601069173
R2_score with original data: 0.9999846601069173
best :-  mul(sin(3), sin(sin(add(cos(s_1), tanh(abs(3))))))
GENERATING PREFERENCE PAIRS
1496
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.3669067716608409
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.11361402859287191
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.0860941980723766
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.08985633855999414
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.061271956168111694
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.059421982610011276
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.05700359449275472
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.04887578882942593
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.04957720934353466
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.04983214567407237
Cycle 4/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg    	std    	min       	max    
0  	0     	9.01889	53.2717	0.00882022	531.878
1  	57    	970.465	9650.98	0.00882022	96996.5
2  	48    	0.360307	1.11306	0.0051243 	9.75035
3  	54    	0.575432	2.16066	0.0051243 	15.811 
4  	64    	292.438 	2906.33	0.0051243 	29210.1
5  	57    	1e+12   	9.94987e+12	0.00488823	1e+14  
6  	60    	10.9258 	106.029    	0.00488823	1065.87
7  	64    	13.5801 	131.684    	0.00488823	1323.79
Best individual: protected_log(protected_sqrt(protected_sqrt(protected_log(4))))
Fitness: (0.004888225458462707,)
R2_score with noisy data: 0.9999498861368477
R2_score with original data: 0.9999498861368477
best :-  protected_log(protected_sqrt(protected_sqrt(protected_log(4))))
GENERATING PREFERENCE PAIRS
1484
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.8283792784121685
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.35676600310885265
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.6388845828011616
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.08195422678741443
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.06761639953188392
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.050222424580129786
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.059379490925545945
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.020066051771140042
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.024720084261193626
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.025555626442653086
current file index :-  1
current file index :-  2
current file index :-  3
1000000
Cycle 1/4
Length of seed expression array :- 67
num_cores  128
67 66
gen	nevals	avg        	std        	min    	max        
0  	0     	9.99997e+11	9.94985e+12	27.0903	9.99997e+13
1  	63    	2.64935e+08	2.63519e+09	27.0903	2.64847e+10
2  	63    	5.84619e+13	5.81688e+14	31.6965	5.84619e+15
3  	67    	106989     	893210     	27.0903	8.80528e+06
4  	58    	7.07664e+24	7.04117e+25	27.0903	7.07664e+26
5  	67    	2.64302e+13	1.8906e+14 	27.0903	1.6e+15    
6  	60    	2.08253e+13	1.45777e+14	27.0903	1.04127e+15
7  	61    	1.90831e+11	1.89875e+12	4.92886	1.90831e+13
Best individual: mul(add(s_1, protected_log(abs(s_2))), s_2)
Fitness: (4.9288556937875025,)
R2_score with noisy data: 0.9999958142363223
R2_score with original data: 0.9999958142363223
best :-  mul(add(s_1, protected_log(abs(s_2))), s_2)
GENERATING PREFERENCE PAIRS
1534
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.4421244889933181
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.3973205690090726
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.3587828150817326
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.3404086898988137
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.3319578848646155
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.33000664647015465
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.3278266021727838
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.3257745615230849
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.32548814245753666
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.3254547938160211
Cycle 2/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg   	std    	min    	max    
0  	0     	693.24	2702.27	33.8471	27380.2
1  	57    	3.49062e+77	3.47312e+78	27.0903	3.49062e+79
2  	62    	1.59479e+83	1.5495e+84 	27.0903	1.55723e+85
3  	51    	1.59561e+48	1.58761e+49	27.5786	1.59561e+50
4  	58    	6.65015e+13	6.61681e+14	27.0903	6.65015e+15
5  	59    	2.73802e+200	inf        	31.8335	2.73802e+202
6  	61    	1.2582e+18  	1.25189e+19	31.8335	1.2582e+20  
7  	61    	1.29367e+14 	1.22736e+15	34.5339	1.23265e+16 
Best individual: mul(s_1, abs(s_2))
Fitness: (27.090273870755205,)
R2_score with noisy data: 0.9999769939532762
R2_score with original data: 0.9999769939532762
best :-  mul(s_1, abs(s_2))
GENERATING PREFERENCE PAIRS
1534
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.25565607154245984
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.19138065613420716
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.16372673597803653
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.18163072050697632
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.15289595159038663
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.15136893527960638
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.14759491951554082
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.1455843090511085
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.14503147097138344
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.14569421776010225
Cycle 3/4
Length of seed expression array :- 75
num_cores  128
75 25
gen	nevals	avg        	std        	min    	max        
0  	0     	7.03348e+13	6.92039e+14	50.8256	6.95561e+15
1  	56    	2.0125e+84 	2.00241e+85	50.8256	2.0125e+86 
2  	48    	1.49764e+82	1.04015e+83	27.0903	7.43037e+83
3  	50    	8.56432e+06	8.41951e+07	50.8256	8.46268e+08
4  	55    	2.0685e+83 	2.04943e+84	27.0903	2.05982e+85
5  	67    	inf        	nan        	50.8256	inf        
6  	54    	inf        	nan        	27.0903	inf        
7  	70    	3.28347e+33	3.26701e+34	40.44  	3.28347e+35
Best individual: mul(abs(s_2), s_1)
Fitness: (27.090273870755205,)
R2_score with noisy data: 0.9999769939532762
R2_score with original data: 0.9999769939532762
best :-  mul(abs(s_2), s_1)
GENERATING PREFERENCE PAIRS
1534
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.10911674672668407
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.17459676114934863
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.09950371963265284
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.058043120809233406
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.044512080291989185
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.048378982532779696
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.04708394645775075
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.0485889992959475
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.048327554978064964
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.048831332222283384
Cycle 4/4
Length of seed expression array :- 75
num_cores  128
75 75
gen	nevals	avg   	std        	min    	max        
0  	0     	759856	5.30843e+06	64.6406	3.79188e+07
1  	55    	2.34338e+79	2.33163e+80	46.3741	2.34338e+81
2  	51    	2.34662e+80	2.33486e+81	46.3741	2.34662e+82
3  	56    	inf        	nan        	46.3741	inf        
4  	64    	inf        	nan        	34.5339	inf        
5  	65    	2.98896e+30	2.97398e+31	34.5339	2.98896e+32
6  	64    	3.74375e+23	3.72498e+24	33.8471	3.74375e+25
7  	73    	9.16786e+116	9.12191e+117	33.8471	9.16786e+118
Best individual: mul(4, s_1)
Fitness: (33.84714608846767,)
R2_score with noisy data: 0.9999712557714221
R2_score with original data: 0.9999712557714221
best :-  mul(4, s_1)
GENERATING PREFERENCE PAIRS
1482
TRAINING THE TRANSFORMER
TESTING
Epoch [1/10], TEST Loss: 0.5424530263572027
TRAINING THE TRANSFORMER
TESTING
Epoch [2/10], TEST Loss: 0.12540948588626585
TRAINING THE TRANSFORMER
TESTING
Epoch [3/10], TEST Loss: 0.03844400218536168
TRAINING THE TRANSFORMER
TESTING
Epoch [4/10], TEST Loss: 0.023054308517944558
TRAINING THE TRANSFORMER
TESTING
Epoch [5/10], TEST Loss: 0.0068494810345597085
TRAINING THE TRANSFORMER
TESTING
Epoch [6/10], TEST Loss: 0.004384727772224242
TRAINING THE TRANSFORMER
TESTING
Epoch [7/10], TEST Loss: 0.00251868319752437
TRAINING THE TRANSFORMER
TESTING
Epoch [8/10], TEST Loss: 0.002496570481364999
TRAINING THE TRANSFORMER
TESTING
Epoch [9/10], TEST Loss: 0.0023982948921768945
TRAINING THE TRANSFORMER
TESTING
Epoch [10/10], TEST Loss: 0.0022707995601047733
current file index :-  4
1000000
Cycle 1/4
Length of seed expression array :- 75
num_cores  128
75 68
gen	nevals	avg        	std        	min        	max        
0  	0     	7.80848e+11	7.76934e+12	1.05059e-12	7.80848e+13
1  	59    	inf        	nan        	1.05059e-12	inf        
2  	63    	2.54983e+31	2.53705e+32	1.05059e-12	2.54983e+33
3  	59    	9.63614e+200	inf        	1.05059e-12	9.63614e+202
4  	56    	6.1898e+200 	inf        	1.05059e-12	6.1898e+202 
5  	63    	1.12864e+164	inf        	1.05059e-12	1.12861e+166
6  	64    	2.46963e+75 	2.45725e+76	1.05059e-12	2.46963e+77 
7  	63    	5.09966e+31 	3.56976e+32	1.05059e-12	2.54983e+33 
Best individual: mul(mul(mul(s_1, s_2), s_3), protected_pow(s_4, -1))
Fitness: (1.050589320089321e-12,)
R2_score with noisy data: 1.0
R2_score with original data: 1.0
best :-  mul(mul(mul(s_1, s_2), s_3), protected_pow(s_4, -1))
GENERATING PREFERENCE PAIRS
0
